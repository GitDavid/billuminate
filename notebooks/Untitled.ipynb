{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_rankings = {'bill':0, 'title': 1, 'section':2, 'subsection':3, 'paragraph':4, \n",
    "                'subparagraph':5, 'clause':6, 'subclause':7, 'item':8, 'subitem':9, 'subsubitem':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bill',\n",
       " 'title',\n",
       " 'section',\n",
       " 'subsection',\n",
       " 'paragraph',\n",
       " 'subparagraph',\n",
       " 'clause',\n",
       " 'subclause',\n",
       " 'item',\n",
       " 'subitem',\n",
       " 'subsubitem']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_tags = list(tag_rankings.keys())\n",
    "ordered_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_rankings = {key: value for (value, key) in enumerate(ordered_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bill': 0,\n",
       " 'title': 1,\n",
       " 'section': 2,\n",
       " 'subsection': 3,\n",
       " 'paragraph': 4,\n",
       " 'subparagraph': 5,\n",
       " 'clause': 6,\n",
       " 'subclause': 7,\n",
       " 'item': 8,\n",
       " 'subitem': 9,\n",
       " 'subsubitem': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_rankings = {'bill':0, 'title': 1, 'section':2, 'subsection':3, 'paragraph':4, \n",
    "                'subparagraph':5, 'clause':6, 'subclause':7, 'item':8, 'subitem':9, 'subsubitem':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [SOURCE](https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "Z = linkage(similarity_matrix, 'ward')\n",
    "pd.DataFrame(Z, columns=['Document\\Cluster 1', 'Document\\Cluster 2', \n",
    "                         'Distance', 'Cluster Size'], dtype='object')\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "tv_matrix = tv.fit_transform(norm_corpus)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TRAINING = '../data/training_data/'\n",
    "TRAINING_FILES = os.listdir(PATH_TO_TRAINING)\n",
    "file_name = TRAINING_FILES[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainingdata_v1_GLOVEemb100_Education.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(PATH_TO_TRAINING + file_name)\n",
    "del training_data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33333, 101)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Option at 0x11e8cc0b8: --filtered>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# parse commandline arguments\n",
    "op = OptionParser()\n",
    "op.add_option(\"--report\",\n",
    "              action=\"store_true\", dest=\"print_report\",\n",
    "              help=\"Print a detailed classification report.\")\n",
    "op.add_option(\"--chi2_select\",\n",
    "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
    "              help=\"Select some number of features using a chi-squared test\")\n",
    "op.add_option(\"--confusion_matrix\",\n",
    "              action=\"store_true\", dest=\"print_cm\",\n",
    "              help=\"Print the confusion matrix.\")\n",
    "op.add_option(\"--top10\",\n",
    "              action=\"store_true\", dest=\"print_top10\",\n",
    "              help=\"Print ten most discriminative terms per class\"\n",
    "                   \" for every classifier.\")\n",
    "op.add_option(\"--all_categories\",\n",
    "              action=\"store_true\", dest=\"all_categories\",\n",
    "              help=\"Whether to use all categories or not.\")\n",
    "op.add_option(\"--use_hashing\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Use a hashing vectorizer.\")\n",
    "op.add_option(\"--n_features\",\n",
    "              action=\"store\", type=int, default=2 ** 16,\n",
    "              help=\"n_features when using the hashing vectorizer.\")\n",
    "op.add_option(\"--filtered\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Remove newsgroup information that is easily overfit: \"\n",
    "                   \"headers, signatures, and quoting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_interactive():\n",
    "    return not hasattr(sys.modules['__main__'], '__file__')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Usage: ipykernel_launcher.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --report              Print a detailed classification report.\n",
      "  --chi2_select=SELECT_CHI2\n",
      "                        Select some number of features using a chi-squared\n",
      "                        test\n",
      "  --confusion_matrix    Print the confusion matrix.\n",
      "  --top10               Print ten most discriminative terms per class for\n",
      "                        every classifier.\n",
      "  --all_categories      Whether to use all categories or not.\n",
      "  --use_hashing         Use a hashing vectorizer.\n",
      "  --n_features=N_FEATURES\n",
      "                        n_features when using the hashing vectorizer.\n",
      "  --filtered            Remove newsgroup information that is easily overfit:\n",
      "                        headers, signatures, and quoting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# work-around for Jupyter notebook and IPython console\n",
    "argv = [] if is_interactive() else sys.argv[1:]\n",
    "(opts, args) = op.parse_args(argv)\n",
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['not_summary', 'in_summary']#, 'is_summary']\n",
    "target_names = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not_summary', 'in_summary']\n"
     ]
    }
   ],
   "source": [
    "print(categories if categories else \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_000</th>\n",
       "      <th>embed_001</th>\n",
       "      <th>embed_002</th>\n",
       "      <th>embed_003</th>\n",
       "      <th>embed_004</th>\n",
       "      <th>embed_005</th>\n",
       "      <th>embed_006</th>\n",
       "      <th>embed_007</th>\n",
       "      <th>embed_008</th>\n",
       "      <th>embed_009</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_091</th>\n",
       "      <th>embed_092</th>\n",
       "      <th>embed_093</th>\n",
       "      <th>embed_094</th>\n",
       "      <th>embed_095</th>\n",
       "      <th>embed_096</th>\n",
       "      <th>embed_097</th>\n",
       "      <th>embed_098</th>\n",
       "      <th>embed_099</th>\n",
       "      <th>in_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.056422</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.268965</td>\n",
       "      <td>-0.172620</td>\n",
       "      <td>0.155507</td>\n",
       "      <td>-0.054346</td>\n",
       "      <td>-0.233235</td>\n",
       "      <td>0.229572</td>\n",
       "      <td>-0.335401</td>\n",
       "      <td>0.084562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117333</td>\n",
       "      <td>-0.206922</td>\n",
       "      <td>0.261570</td>\n",
       "      <td>-0.330002</td>\n",
       "      <td>-0.079763</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>-0.191006</td>\n",
       "      <td>0.519074</td>\n",
       "      <td>-0.108229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058652</td>\n",
       "      <td>-0.117069</td>\n",
       "      <td>0.460318</td>\n",
       "      <td>0.040631</td>\n",
       "      <td>0.370035</td>\n",
       "      <td>0.216636</td>\n",
       "      <td>-0.342123</td>\n",
       "      <td>0.053123</td>\n",
       "      <td>-0.647005</td>\n",
       "      <td>0.246054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191864</td>\n",
       "      <td>-0.173184</td>\n",
       "      <td>0.678500</td>\n",
       "      <td>-0.333590</td>\n",
       "      <td>-0.077078</td>\n",
       "      <td>-0.273590</td>\n",
       "      <td>-0.433252</td>\n",
       "      <td>0.637059</td>\n",
       "      <td>-0.069550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.023605</td>\n",
       "      <td>0.197405</td>\n",
       "      <td>0.155603</td>\n",
       "      <td>0.023352</td>\n",
       "      <td>0.058235</td>\n",
       "      <td>0.056801</td>\n",
       "      <td>-0.164208</td>\n",
       "      <td>0.169467</td>\n",
       "      <td>-0.421830</td>\n",
       "      <td>0.204527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132863</td>\n",
       "      <td>-0.150759</td>\n",
       "      <td>0.347252</td>\n",
       "      <td>-0.492464</td>\n",
       "      <td>0.248988</td>\n",
       "      <td>-0.213403</td>\n",
       "      <td>-0.430866</td>\n",
       "      <td>0.720138</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.022930</td>\n",
       "      <td>0.017849</td>\n",
       "      <td>0.287668</td>\n",
       "      <td>-0.084799</td>\n",
       "      <td>0.055446</td>\n",
       "      <td>0.166762</td>\n",
       "      <td>-0.121587</td>\n",
       "      <td>0.391760</td>\n",
       "      <td>-0.277280</td>\n",
       "      <td>0.053404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221300</td>\n",
       "      <td>-0.289683</td>\n",
       "      <td>0.370285</td>\n",
       "      <td>-0.378162</td>\n",
       "      <td>0.040656</td>\n",
       "      <td>-0.133651</td>\n",
       "      <td>-0.321041</td>\n",
       "      <td>0.416759</td>\n",
       "      <td>-0.088398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.157584</td>\n",
       "      <td>0.207188</td>\n",
       "      <td>0.077027</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>0.033980</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>-0.326005</td>\n",
       "      <td>0.293169</td>\n",
       "      <td>-0.344101</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149532</td>\n",
       "      <td>-0.144093</td>\n",
       "      <td>0.313850</td>\n",
       "      <td>-0.448105</td>\n",
       "      <td>0.124416</td>\n",
       "      <td>-0.253026</td>\n",
       "      <td>-0.427831</td>\n",
       "      <td>0.575843</td>\n",
       "      <td>0.057013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   embed_000  embed_001  embed_002  embed_003  embed_004  embed_005  \\\n",
       "0  -0.056422   0.022105   0.268965  -0.172620   0.155507  -0.054346   \n",
       "1   0.058652  -0.117069   0.460318   0.040631   0.370035   0.216636   \n",
       "2  -0.023605   0.197405   0.155603   0.023352   0.058235   0.056801   \n",
       "3  -0.022930   0.017849   0.287668  -0.084799   0.055446   0.166762   \n",
       "4   0.157584   0.207188   0.077027   0.016410   0.033980   0.275900   \n",
       "\n",
       "   embed_006  embed_007  embed_008  embed_009  ...  embed_091  embed_092  \\\n",
       "0  -0.233235   0.229572  -0.335401   0.084562  ...  -0.117333  -0.206922   \n",
       "1  -0.342123   0.053123  -0.647005   0.246054  ...  -0.191864  -0.173184   \n",
       "2  -0.164208   0.169467  -0.421830   0.204527  ...  -0.132863  -0.150759   \n",
       "3  -0.121587   0.391760  -0.277280   0.053404  ...  -0.221300  -0.289683   \n",
       "4  -0.326005   0.293169  -0.344101   0.304878  ...  -0.149532  -0.144093   \n",
       "\n",
       "   embed_093  embed_094  embed_095  embed_096  embed_097  embed_098  \\\n",
       "0   0.261570  -0.330002  -0.079763  -0.031500  -0.191006   0.519074   \n",
       "1   0.678500  -0.333590  -0.077078  -0.273590  -0.433252   0.637059   \n",
       "2   0.347252  -0.492464   0.248988  -0.213403  -0.430866   0.720138   \n",
       "3   0.370285  -0.378162   0.040656  -0.133651  -0.321041   0.416759   \n",
       "4   0.313850  -0.448105   0.124416  -0.253026  -0.427831   0.575843   \n",
       "\n",
       "   embed_099  in_summary  \n",
       "0  -0.108229           1  \n",
       "1  -0.069550           0  \n",
       "2   0.159700           1  \n",
       "3  -0.088398           0  \n",
       "4   0.057013           1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data.drop(columns=['in_summary'])\n",
    "y = training_data[['in_summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,\n",
    " X_test,\n",
    " y_train,\n",
    " y_test) = train_test_split(X, y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_size_mb = size_mb(X_train)\n",
    "data_test_size_mb = size_mb(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24999 documents - 0.001MB (training set)\n",
      "8334 documents - 0.001MB (test set)\n",
      "2 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(X_train), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(X_test), data_test_size_mb))\n",
    "print(\"%d categories\" % len(target_names))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONLY NECESSARY FOR WORD INPUTS\n",
    "```python\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if opts.use_hashing:\n",
    "    vectorizer = HashingVectorizer(stop_words='english', alternate_sign=False,\n",
    "                                   n_features=opts.n_features)\n",
    "    X_train = vectorizer.transform(data_train.data)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "if opts.use_hashing:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "if opts.select_chi2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "          opts.select_chi2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names:\n",
    "        # keep selected feature names\n",
    "        feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if opts.print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if opts.print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if opts.print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 10.586s\n",
      "test time:  0.002s\n",
      "accuracy:   0.883\n",
      "dimensionality: 100\n",
      "density: 0.870000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "result = benchmark(LinearSVC(penalty=penalty, dual=False,\n",
    "                                       tol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LinearSVC', 0.8833693304535637, 10.585973978042603, 0.0022149085998535156)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='sag',\n",
      "        tol=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:839: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.719s\n",
      "test time:  0.004s\n",
      "accuracy:   0.883\n",
      "dimensionality: 100\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=50, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.062s\n",
      "test time:  0.002s\n",
      "accuracy:   0.225\n",
      "dimensionality: 100\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              early_stopping=False, fit_intercept=True, loss='hinge',\n",
      "              max_iter=50, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.085s\n",
      "test time:  0.002s\n",
      "accuracy:   0.854\n",
      "dimensionality: 100\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.150s\n",
      "test time:  61.412s\n",
      "accuracy:   0.877\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 22.846s\n",
      "test time:  0.255s\n",
      "accuracy:   0.921\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.647s\n",
      "test time:  0.007s\n",
      "accuracy:   0.883\n",
      "dimensionality: 100\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.421s\n",
      "test time:  0.002s\n",
      "accuracy:   0.883\n",
      "dimensionality: 100\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 9.831s\n",
      "test time:  0.002s\n",
      "accuracy:   0.883\n",
      "dimensionality: 100\n",
      "density: 0.820000\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.928s\n",
      "test time:  0.002s\n",
      "accuracy:   0.883\n",
      "dimensionality: 100\n",
      "density: 0.600000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1.042s\n",
      "test time:  0.002s\n",
      "accuracy:   0.883\n",
      "dimensionality: 100\n",
      "density: 0.750000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.021s\n",
      "test time:  0.014s\n",
      "accuracy:   0.397\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6fae2a733199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Naive Bayes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBernoulliNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mComplementNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-eeacc392387f>\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(clf)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train time: %0.3fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtrain_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    608\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[1;32m    609\u001b[0m                                        dtype=np.float64)\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=50, tol=1e-3), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=50, tol=1e-3),\n",
    "         \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n",
    "                                       tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RidgeClassifier',\n",
       "  0.8833693304535637,\n",
       "  0.7188811302185059,\n",
       "  0.004220247268676758),\n",
       " ('Perceptron',\n",
       "  0.22450203983681305,\n",
       "  0.06226491928100586,\n",
       "  0.0016849040985107422),\n",
       " ('PassiveAggressiveClassifier',\n",
       "  0.8539716822654188,\n",
       "  0.0849909782409668,\n",
       "  0.0018069744110107422),\n",
       " ('KNeighborsClassifier',\n",
       "  0.8774898008159348,\n",
       "  0.14961504936218262,\n",
       "  61.41171884536743),\n",
       " ('RandomForestClassifier',\n",
       "  0.9208063354931606,\n",
       "  22.846206188201904,\n",
       "  0.2554140090942383),\n",
       " ('LinearSVC', 0.8833693304535637, 0.6468830108642578, 0.00700068473815918),\n",
       " ('SGDClassifier',\n",
       "  0.8834893208543316,\n",
       "  0.42073988914489746,\n",
       "  0.002087831497192383),\n",
       " ('LinearSVC', 0.8833693304535637, 9.83080005645752, 0.002057790756225586),\n",
       " ('SGDClassifier',\n",
       "  0.8834893208543316,\n",
       "  0.9276154041290283,\n",
       "  0.0021266937255859375),\n",
       " ('SGDClassifier',\n",
       "  0.8834893208543316,\n",
       "  1.0417311191558838,\n",
       "  0.0019719600677490234),\n",
       " ('NearestCentroid',\n",
       "  0.39656827453803695,\n",
       "  0.020511150360107422,\n",
       "  0.014255046844482422)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "train time: 0.073s\n",
      "test time:  0.021s\n",
      "accuracy:   0.430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(GaussianNB()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        max_features=None, no...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/melissaferrari/anaconda3/envs/congress_py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 21.045s\n",
      "test time:  0.003s\n",
      "accuracy:   0.883\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cbe9d5a5b9f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclf_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/congress_py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2332\u001b[0m     \"\"\"\n\u001b[1;32m   2333\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2334\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/congress_py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
